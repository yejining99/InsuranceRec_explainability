"""
ë³´í—˜ ì¶”ì²œ ì‹œìŠ¤í…œ ë©”ì¸ ì‹¤í–‰ íŒŒì¼
ì „ì²´ íŒŒì´í”„ë¼ì¸: ë°ì´í„° ì „ì²˜ë¦¬ â†’ ëª¨ë¸ í•™ìŠµ â†’ ì„±ëŠ¥ í‰ê°€ â†’ ì–´í…ì…˜ ë¶„ì„
"""

import os
import logging
from datetime import datetime
from typing import Tuple, Dict, List

from data_preprocessing import preprocess_insurance_data
from data_converter import InsuranceDataConverter
from model_trainer import InsuranceEmbeddingTrainer, split_data_by_date
from attention_analyzer import analyze_test_samples
from config import MODEL_PATHS, TRAINING_CONFIG


def main_training_pipeline(file_path: str = None, 
                          sample_size: int = None,
                          enable_attention_analysis: bool = True):
    """
    ë³´í—˜ ì¶”ì²œ ëª¨ë¸ ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸
    
    Args:
        file_path: ë°ì´í„° íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ configì—ì„œ ê°€ì ¸ì˜´)
        sample_size: ìƒ˜í”Œ í¬ê¸° (Noneì´ë©´ ì „ì²´ ë°ì´í„° ì‚¬ìš©)
        enable_attention_analysis: ì–´í…ì…˜ ë¶„ì„ ìˆ˜í–‰ ì—¬ë¶€
    """
    
    logging.info("ğŸ¯ ë³´í—˜ ì¶”ì²œ ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    start_time = datetime.now()
    
    try:
        # 1. ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¡œë”©
        logging.info("=" * 60)
        logging.info("ğŸš€ 1ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¡œë”©")
        logging.info("=" * 60)
        
        fin_aggregated_df = preprocess_insurance_data(file_path)
        
        # ìƒ˜í”Œ í¬ê¸° ì œí•œ (í…ŒìŠ¤íŠ¸ìš©)
        if sample_size:
            fin_aggregated_df = fin_aggregated_df.head(sample_size)
            logging.info(f"ğŸ“Š ìƒ˜í”Œ í¬ê¸° ì œí•œ: {sample_size}ê°œ")
        
        # 2. ë°ì´í„° ë³€í™˜ (Query-Value pair)
        logging.info("=" * 60)
        logging.info("ğŸ”„ 2ë‹¨ê³„: Query-Value pair ë³€í™˜")
        logging.info("=" * 60)
        
        converter = InsuranceDataConverter()
        result_df = converter.convert_dataframe(fin_aggregated_df)
        
        # 3. ë°ì´í„° ë¶„í• 
        logging.info("=" * 60)
        logging.info("ğŸ“Š 3ë‹¨ê³„: ë°ì´í„° ë¶„í• ")
        logging.info("=" * 60)
        
        train_df, eval_df, test_df = split_data_by_date(result_df)
        
        # 4. ëª¨ë¸ í•™ìŠµ
        logging.info("=" * 60)
        logging.info("ğŸš€ 4ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ")
        logging.info("=" * 60)
        
        trainer = InsuranceEmbeddingTrainer()
        
        # ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ (ì„ íƒì )
        try:
            trainer.load_pretrained_model()
            
            # ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ë¡œ ìƒ˜í”Œ ì„ë² ë”© í…ŒìŠ¤íŠ¸
            sample_sentences = train_df['query'].head(3).tolist()
            embeddings = trainer.get_embeddings_manual(sample_sentences)
            logging.info(f"âœ… ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ì„ë² ë”© í…ŒìŠ¤íŠ¸: {embeddings.shape}")
            
        except Exception as e:
            logging.warning(f"âš ï¸ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            logging.info("ğŸŒ ì˜¨ë¼ì¸ ëª¨ë¸ ì‚¬ìš©ìœ¼ë¡œ ì „í™˜")
        
        # ëª¨ë¸ í•™ìŠµ ì‹¤í–‰
        trainer.train_model_with_safe_evaluator(
            train_df=train_df,
            eval_df=eval_df,
            epochs=TRAINING_CONFIG['epochs'],
            batch_size=TRAINING_CONFIG['batch_size'],
            learning_rate=TRAINING_CONFIG['learning_rate']
        )
        
        # 5. ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
        logging.info("=" * 60)
        logging.info("ğŸ“Š 5ë‹¨ê³„: ëª¨ë¸ ì„±ëŠ¥ í‰ê°€")
        logging.info("=" * 60)
        
        metrics = trainer.evaluate_model_performance(test_df)
        
        print("\n" + "=" * 60)
        print("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼")
        print("=" * 60)
        for metric, value in metrics.items():
            print(f"{metric:20}: {value:.4f}")
        print("=" * 60)
        
        # 6. ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
        logging.info("ğŸ¯ 6ë‹¨ê³„: ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
        
        test_query = test_df['query'].iloc[0]
        test_values = test_df['value'].head(10).tolist()
        
        recommendations = trainer.recommend_products(
            user_query=test_query,
            product_values=test_values,
            top_k=5
        )
        
        print("\n" + "=" * 60)
        print("ğŸ¯ ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        print("=" * 60)
        print(f"ğŸ‘¤ ì‚¬ìš©ì ì¿¼ë¦¬: {test_query[:100]}...")
        print("\nğŸ“‹ ì¶”ì²œ ìƒí’ˆ:")
        for i, (idx, score) in enumerate(recommendations):
            print(f"{i+1}. ìœ ì‚¬ë„: {score:.4f}")
            print(f"   ìƒí’ˆ: {test_values[idx][:100]}...")
            print()
        
        # 7. ì–´í…ì…˜ ë¶„ì„ (ì„ íƒì )
        if enable_attention_analysis:
            logging.info("=" * 60)
            logging.info("ğŸ” 7ë‹¨ê³„: ì–´í…ì…˜ ë¶„ì„")
            logging.info("=" * 60)
            
            try:
                analyzer, attention_results = analyze_test_samples(
                    test_df=test_df.head(20),  # ìƒìœ„ 20ê°œ ìƒ˜í”Œë§Œ
                    model_path=MODEL_PATHS['trained_model'],
                    sample_size=3
                )
                logging.info("âœ… ì–´í…ì…˜ ë¶„ì„ ì™„ë£Œ")
            except Exception as e:
                logging.warning(f"âš ï¸ ì–´í…ì…˜ ë¶„ì„ ì‹¤íŒ¨: {e}")
                attention_results = None
        else:
            attention_results = None
        
        # 8. ê²°ê³¼ ì €ì¥ í™•ì¸
        if os.path.exists(trainer.output_path):
            logging.info(f"âœ… ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {trainer.output_path}")
        else:
            logging.error(f"âŒ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {trainer.output_path}")
        
        # íŒŒì´í”„ë¼ì¸ ì™„ë£Œ
        end_time = datetime.now()
        elapsed_time = end_time - start_time
        
        print("\n" + "=" * 60)
        print("ğŸ‰ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
        print("=" * 60)
        print(f"â±ï¸  ì´ ì†Œìš” ì‹œê°„: {elapsed_time}")
        print(f"ğŸ“Š ì²˜ë¦¬ëœ ë°ì´í„°: {len(result_df)}ê°œ ë ˆì½”ë“œ")
        print(f"ğŸ† ìµœì¢… ì„±ëŠ¥ (F1 Score): {metrics.get('f1_score', 0):.4f}")
        print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {trainer.output_path}")
        print("=" * 60)
        
        return {
            'trainer': trainer,
            'metrics': metrics,
            'test_df': test_df,
            'attention_results': attention_results,
            'elapsed_time': elapsed_time
        }
    
    except Exception as e:
        logging.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise


def quick_test_pipeline(sample_size: int = 100):
    """ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ê°„ì†Œí™”ëœ íŒŒì´í”„ë¼ì¸"""
    logging.info("ğŸ§ª ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    
    return main_training_pipeline(
        sample_size=sample_size,
        enable_attention_analysis=False
    )


def load_and_test_trained_model(model_path: str = None, test_queries: List[str] = None):
    """í•™ìŠµëœ ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ í…ŒìŠ¤íŠ¸"""
    logging.info("ğŸ” í•™ìŠµëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸")
    
    if model_path is None:
        model_path = MODEL_PATHS['trained_model']
    
    # ëª¨ë¸ ë¡œë“œ
    trainer = InsuranceEmbeddingTrainer()
    try:
        trainer.load_trained_model(model_path)
        logging.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_path}")
    except Exception as e:
        logging.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    if test_queries is None:
        test_queries = [
            "35ì„¸ ë‚¨ì„± ê³ ê°ìœ¼ë¡œ ì§ì—…ë“±ê¸‰ 1ê¸‰ ì‚¬ë¬´ì§, ìƒí•´ë“±ê¸‰ 1ê¸‰ ë§¤ìš°ë‚®ìŒì— í•´ë‹¹í•©ë‹ˆë‹¤. í¬ë§í•˜ëŠ” ë³´í—˜ë£ŒëŠ” 5~10ë§Œì› ì´í•˜ì´ê³  ì•”, ì‚¬ë§ í…Œë§ˆì— íŠ¹ë³„í•œ ê´€ì‹¬ì´ ìˆìŠµë‹ˆë‹¤.",
            "42ì„¸ ì—¬ì„± ê³ ê°ìœ¼ë¡œ ì§ì—…ë“±ê¸‰ 2ê¸‰ ì¼ë°˜ì§, ìƒí•´ë“±ê¸‰ 3ê¸‰ ë‚®ìŒì— í•´ë‹¹í•©ë‹ˆë‹¤. í¬ë§í•˜ëŠ” ë³´í—˜ë£ŒëŠ” 10~15ë§Œì› ì´í•˜ì´ê³  ì¹˜ë§¤, ë‡Œí˜ˆê´€ì§ˆí™˜ í…Œë§ˆì— íŠ¹ë³„í•œ ê´€ì‹¬ì´ ìˆìŠµë‹ˆë‹¤."
        ]
    
    # ìƒ˜í”Œ ìƒí’ˆ ì •ë³´ (ì‹¤ì œ ìš´ì˜ì‹œì—ëŠ” DBì—ì„œ ê°€ì ¸ì˜´)
    sample_products = [
        "ë¬´ë°°ë‹¹ ì¢…í•©ë³´í—˜ ìƒí’ˆìœ¼ë¡œ ì›” ë³´í—˜ë£Œ 8ë§Œ 5ì²œì›ì…ë‹ˆë‹¤. ë‚©ì…ì¡°ê±´ì€ 20ë…„ë‚©ì´ë©° í‘œì¤€í˜• ë°©ì‹ì„ ì ìš©í•©ë‹ˆë‹¤.",
        "ê±´ê°•ë³´í—˜ í”ŒëŸ¬ìŠ¤ ìƒí’ˆìœ¼ë¡œ ì›” ë³´í—˜ë£Œ 12ë§Œì›ì…ë‹ˆë‹¤. ë‚©ì…ì¡°ê±´ì€ 15ë…„ë‚©ì´ë©° í•´ì§€í™˜ê¸‰ê¸ˆë¯¸ì§€ê¸‰í˜• ë°©ì‹ì„ ì ìš©í•©ë‹ˆë‹¤.",
        "ì•”ë³´í—˜ í”„ë¦¬ë¯¸ì—„ ìƒí’ˆìœ¼ë¡œ ì›” ë³´í—˜ë£Œ 6ë§Œì›ì…ë‹ˆë‹¤. ë‚©ì…ì¡°ê±´ì€ ì „ê¸°ë‚©ì´ë©° í‘œì¤€í˜• ë°©ì‹ì„ ì ìš©í•©ë‹ˆë‹¤."
    ]
    
    # ì¶”ì²œ í…ŒìŠ¤íŠ¸
    print("\n" + "=" * 60)
    print("ğŸ¯ í•™ìŠµëœ ëª¨ë¸ ì¶”ì²œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    for i, query in enumerate(test_queries):
        print(f"\nğŸ” í…ŒìŠ¤íŠ¸ {i+1}")
        print(f"ğŸ‘¤ ê³ ê° í”„ë¡œí•„: {query}")
        print("\nğŸ“‹ ì¶”ì²œ ê²°ê³¼:")
        
        recommendations = trainer.recommend_products(
            user_query=query,
            product_values=sample_products,
            top_k=3
        )
        
        for j, (idx, score) in enumerate(recommendations):
            print(f"  {j+1}. ìœ ì‚¬ë„: {score:.4f} - {sample_products[idx]}")
        print()
    
    return trainer


if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        format='%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S',
        level=logging.INFO
    )
    
    print("ğŸš€ ë³´í—˜ ì¶”ì²œ ì‹œìŠ¤í…œ ë©”ì¸ íŒŒì´í”„ë¼ì¸")
    print("=" * 60)
    print("ì„ íƒí•˜ì„¸ìš”:")
    print("1. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ë°ì´í„° ì „ì²˜ë¦¬ â†’ í•™ìŠµ â†’ í‰ê°€ â†’ ì–´í…ì…˜ ë¶„ì„)")
    print("2. ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (ì†ŒëŸ‰ ë°ì´í„°ë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)")
    print("3. í•™ìŠµëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸ (ê¸°ì¡´ ëª¨ë¸ ë¡œë“œí•˜ì—¬ ì¶”ì²œ í…ŒìŠ¤íŠ¸)")
    print("=" * 60)
    
    choice = input("ì„ íƒ (1/2/3): ").strip()
    
    try:
        if choice == "1":
            print("ğŸ¯ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            results = main_training_pipeline()
            
        elif choice == "2":
            print("ğŸ§ª ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
            results = quick_test_pipeline(sample_size=200)
            
        elif choice == "3":
            print("ğŸ” í•™ìŠµëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
            trainer = load_and_test_trained_model()
            
        else:
            print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. 1, 2, 3 ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        logging.error(f"Main pipeline error: {e}", exc_info=True) 